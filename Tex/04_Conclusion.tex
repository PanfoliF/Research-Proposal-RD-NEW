% !TeX root = ../Tex/main.tex
\section{Limitations}
From the very first page, in this paper I adopted a transparet approach. Therefore, this section highlights all limitation of the analysis conducted so far. In this way, constructive criticism become active part of the scientific process.

I noticed three weakeness of the identification strategy:
\begin{itemize}
    \item[-] Omitted Variable Bias.
    \item[-] Provide tests for observable implications in as many as possible narrow, focused, controlled circumstances (\cite{}).
    \item[-] Do not include control variables that are a consequence of the key IV\parencite[chap.~8; pp.~163--182]{siebererSelectingIndependentVariables2007}.
\end{itemize}

Omitted Variable Bias is a common burden of all empirical scientists. There is no way to include all possible sources of variation in the identification strategy and hampers the possibility of identifiyng the "perfect" causal mechanism. However, there are painkiller to this issue. They do not come from causal inference or econometrics. Instead, they come from institutional and qualitative knowledge of the topic under study.

Thus, we can reassure the reader of the reliability of the empirical result deepening the qualitative knowledge of the problem at stake.

\vspace*{1em}
A second important limit of this study comes from the fact that the more we generilise the results, the less we can be sure of what we state. Empirical tests have increadible internal validity. Nonetheless, they all suffer of a noticeable restriction, namely external validity. The identification strategy is solid only when we test the causal mechanism in data it was though to work for. When we appkly the identification strategy to external data, coming from a similar data generating process, the rusults tend to become fuzzy, and the ground of the analysis becomes slippery. 

\vspace*{1em}
Eventually, we have another source of doubts about the research proposal.
Let's imagin a state investing more in school with better tests scores or with lower failure rates. In this way, school managers or regional governments are forced to act in accordance with an incentives scheme.

However, if this were the case for Brazil, there would be a huge bais in the identification strategy used so far. This bias is due to the fact that the outcome variable (test score for example) shapes investments in the school infrastracture, that at the same time influences students performances.

Further exploration of the institutioinal setting can shed light on this issue.

\section*{Conclusion}
This research proposal sets out to turn a familiar policy question--what actually improves educational outcomes?--into an empirical design for the Brazilian case. Building on a panel framework, the project is motivated by a core inferential ambition: identify credible causal effects.

\vspace*{1em}
Two conceptual contributions structure the empirical strategy. First, the proposal distinguishes between two outcome margins: first, standardized test performance (the "extensive margin"), and secondly, failure rates (the "intensive margin"). This distinction is meant to reveal whether improvements in observed performance reflect genuine learning gains, changes in selection into testing, shifts in promotion standards, or other institutional mechanisms. Second, the project operationalizes "teacher quality" through measurable proxies--teachers' education and class size--then embeds these in a causal framework that explicitly anticipates confounding, as illustrated by the proposed causal DAG.

\vspace*{1em}
From the standpoint of methods emplyed, the design combines fixed-effects panel regressions with a Difference-in-Differences (DinD). The fixed-effects architecture (municipality, state, and year) is intended to absorb time-invariant heterogeneity across places and common national shocks across years.

\vspace*{1em}
The DiD is proposed as a second line of support: by focusing on changes induced by reforms, it aims to isolate the marginal effect of shifts in educational inputs from other background trends. In policy terms, this is the kind of design that can speak to decision-makers: its targets are realistically adjustable--teacher qualifications, class size, infrastructure. The design asks how changes in these targets map onto outcomes that matter for human capital formation.

\vspace*{1em}
At the same time, the proposal is transparent about what could go wrong. Omitted variable bias remains the classic specter: even with extensive fixed effects and controls, some determinants of educational performance (local political capacity, school leadership quality, household shocks, informal labor dynamics) may vary over time and correlate with both inputs and outcomes.

External validity is the second constraint: estimates that are internally persuasive in one institutional setting, may not apply cleanly to other contexts or periods.

A third risk is reverse causality: performance itself may shape investment, producing a feedback loop in which outcomes partially determine the "treatments" meant to explain them. This is especially salient in contexts where funding formulas, administrative incentives, or reputational competition allocate resources based on observable performance.

\vspace*{1em}
These limitations do not invalidate the design; they specify the conditions under which it can succeed. In practical terms, they point toward concrete refinements that would elevate the proposal from a promising design to a highly persuasive empirical study.

The most important is institutional context: mapping the precise timing and scope of the targeted reforms and documenting whether--and how--funding and administrative responses are conditioned on performance is crucial for the credibility of the study.

Eventually, the "two-margins" structure proposes a richer interpretation of mechanisms: if teacher quality improves test scores but not failure rates (or vice versa), that divergence is analytically meaningful and can adjudicate between competing narratives about learning, retention policies, and classroom sorting.

\vspace*{1em}
In sum, the proposal's value lies in its attempt to convert a broad and politically consequential question into a design that can generate defensible causal claims. Brazil is not merely an interesting case; its federal structure, policy variation, and the availability of granular panel data make it a powerful empirical laboratory for education policy research. If the project successfully integrates its econometric strategy with careful institutional analysis it can offer findings that are both academically informative and directly relevant to policy choices.

%------- Acknowledgements -------
\subsubsection*{Acknowledgements}
Artificial intelligence-based tools were employed solely to improve linguistic clarity and grammar. No AI system contributed to the development of the research questions, theoretical framework or conclusions presented in this paper.